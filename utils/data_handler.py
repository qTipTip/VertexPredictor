import json
import pathlib

import numpy as np
import torch
import torchvision
from PIL import Image


def process_polygon(polygon, polygon_resolution=28, cropped_image_size=224, max_polygon_length=60):
    """
    We superimpose a grid of size polygon_resolution*polygon_resolution over the cropped image.
    We then one-hot-encode the polygon by creating a polygon_resolution*polygon_resolution array of ints,
    where a 0 tells us that there is no vertex present, and a 1 tells us there is a vertex present.
    We need the output to be of a fixed size, so we make sure that every output is of size
    (max_polygon_length, polygon_resolution**2). We also return the edges as an ordering of vertices.

    :param polygon:
    :param polygon_resolution:
    :param cropped_image_size:
    :return:
    """
    assert cropped_image_size % polygon_resolution == 0

    grid_size = cropped_image_size // polygon_resolution

    vertices = torch.zeros((max_polygon_length, polygon_resolution ** 2))
    # if `polygon` contains more vertices than max_polyg1on_length, then we subsample the polygon.
    if len(polygon) > max_polygon_length:
        scale = len(polygon) / max_polygon_length
        subsample_selection = (np.arange(0, max_polygon_length) * scale).astype(np.int)
        polygon = polygon[subsample_selection]

    # Fill in the original polygon vertices.
    for i in range(len(polygon)):
        vertex = polygon[i]
        x, y = vertex[0] // grid_size, vertex[1] // grid_size
        vertex_index = np.ravel_multi_index((x, y), dims=(polygon_resolution, polygon_resolution))
        vertices[i, vertex_index] = 1

    # If the polygon is shorter than max_polygon_length, then we pad the polygon with -1s, that
    # are masked out in the loss-calculation.
    for i in range(len(polygon), max_polygon_length):
        vertices[i, 0] = -1

    return vertices[0], vertices


class CityScapesDataSet(torch.utils.data.Dataset):
    """
    A dataset class for loading the Cityscapes data
    """

    def __init__(self, data_path, max_polygon_length=60, polygon_resolution=28, cropped_image_size=224, device='cpu',
                 data_set_length=None):
        """
        Initialize a CityScapesDataSet by passing in the path to a folder with the following structure:
        data_path/{images,labels} as generated by `utils.process_data`.

        :param data_path: string
        """

        data_path = pathlib.Path(data_path)
        image_path = data_path / 'images'
        label_path = data_path / 'labels'

        self._check_directories(data_path, image_path, label_path)

        self.image_path = image_path
        self.label_path = label_path
        self.images = sorted(list(image_path.glob('*.png')))
        self.labels = sorted(list(label_path.glob('*.json')))
        self.n_data = len(self.images)

        self.max_polygon_length = max_polygon_length
        self.polygon_resolution = polygon_resolution
        self.cropped_image_size = cropped_image_size
        self.device = device
        self.data_set_length = data_set_length

        print(f'Successfully loaded {self.n_data} items from {data_path.resolve()}')

    @staticmethod
    def _check_directories(data_path, image_path, label_path):
        if not data_path.exists():
            raise FileNotFoundError(f"The directory {data_path.resolve()} does not exist.")
        if not image_path.exists():
            raise FileNotFoundError(f"The directory {image_path.resolve()} does not exist.")
        if not label_path.exists():
            raise FileNotFoundError(f"The directory {label_path.resolve()} does not exist.")

    def __getitem__(self, index):
        image_file = self.images[index]
        label_file = self.labels[index]

        try:
            image = Image.open(image_file.resolve()).convert('RGB')
        except FileNotFoundError:
            print(f'The file {image_file.resolve()} could not be opened')
            return None

        try:
            polygon = np.array(json.load(label_file.open())['polygon'])
        except FileNotFoundError:
            print(f'The file {label_file.resolve()} could not be opened')
            return None

        # TODO: Discretize the polygon to a 28x28 grid, so the label output always is of the same shape!
        first_vertex, vertices = process_polygon(polygon, polygon_resolution=self.polygon_resolution,
                                                 max_polygon_length=self.max_polygon_length,
                                                 cropped_image_size=self.cropped_image_size)

        return torchvision.transforms.ToTensor()(
            image).to(self.device), first_vertex, vertices

    def __len__(self):
        if self.data_set_length is not None:
            return min(self.data_set_length, self.n_data)
        return self.n_data

if __name__ == '__main__':

    data_path =  '../../../CityScapesDataSet/gtFine/output/val'
    data_set = CityScapesDataSet(data_path=data_path)
    img, fv, vertices = data_set[0]
    print(vertices)
    print(fv.shape, vertices.shape)